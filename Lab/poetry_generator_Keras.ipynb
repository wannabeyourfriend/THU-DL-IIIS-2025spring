{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7db8be-df7f-4f64-bdee-2eb962c391ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 6)]               0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 6, 300)            1797600   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 6, 256)           330240    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5990)              9206630   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,334,470\n",
      "Trainable params: 11,334,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "text: 春眠不觉晓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "春期南乐。群眠飒梦。论谁不逢促荷。知觉欲儿松著。晓眷虽甘影来\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "text: 黄河入海流\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "黄函生里吟。河成如带。回入与贪。。侣海逢珠书。大流开赋书。外\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "text: 大美青海\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大。荷好。为美凌径名。酒青窗有荷。复海人五。重林\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, Dense, Flatten, Bidirectional, Embedding, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "puncs = [']', '[', '（', '）', '{', '}', '：', '《', '》']\n",
    "\n",
    "def preprocess_file(Config):\n",
    "    # 语料文本内容\n",
    "    files_content = ''\n",
    "    with open(Config.poetry_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            # 每行的末尾加上\"]\"符号代表一首诗结束\n",
    "            for char in puncs:\n",
    "                line = line.replace(char, \"\")\n",
    "            files_content += line.strip() + \"]\"\n",
    "\n",
    "    words = sorted(list(files_content))\n",
    "    words.remove(']')\n",
    "    counted_words = {}\n",
    "    for word in words:\n",
    "        if word in counted_words:\n",
    "            counted_words[word] += 1\n",
    "        else:\n",
    "            counted_words[word] = 1\n",
    "\n",
    "    # 去掉低频的字\n",
    "    erase = []\n",
    "    for key in counted_words:\n",
    "        if counted_words[key] <= 2:\n",
    "            erase.append(key)\n",
    "    for key in erase:\n",
    "        del counted_words[key]\n",
    "    del counted_words[']']\n",
    "    wordPairs = sorted(counted_words.items(), key=lambda x: -x[1])\n",
    "\n",
    "    words, _ = zip(*wordPairs)\n",
    "    # word到id的映射\n",
    "    word2num = dict((c, i + 1) for i, c in enumerate(words))\n",
    "    num2word = dict((i, c) for i, c in enumerate(words))\n",
    "    word2numF = lambda x: word2num.get(x, 0)\n",
    "    return word2numF, num2word, words, files_content\n",
    "\n",
    "class PoetryModel(object):\n",
    "    def __init__(self, config):\n",
    "        self.model = None\n",
    "        self.do_train = True\n",
    "        self.loaded_model = False\n",
    "        self.config = config\n",
    "\n",
    "        # 文件预处理\n",
    "        self.word2numF, self.num2word, self.words, self.files_content = preprocess_file(self.config)\n",
    "\n",
    "        # 如果模型文件存在则直接加载模型，否则开始训练\n",
    "        if os.path.exists(self.config.weight_file):\n",
    "            self.model = load_model(self.config.weight_file)\n",
    "            self.model.summary()\n",
    "        else:\n",
    "            self.train()\n",
    "        self.do_train = False\n",
    "        self.loaded_model = True\n",
    "\n",
    "    def build_model(self):\n",
    "        '''建立模型'''\n",
    "\n",
    "        # 输入的dimension\n",
    "        input_tensor = Input(shape=(self.config.max_len,))\n",
    "        embedd = Embedding(len(self.num2word) + 2, 300, input_length=self.config.max_len)(input_tensor)\n",
    "        lstm = Bidirectional(GRU(128, return_sequences=True))(embedd)\n",
    "        # dropout = Dropout(0.6)(lstm)\n",
    "        # lstm = LSTM(256)(dropout)\n",
    "        # dropout = Dropout(0.6)(lstm)\n",
    "        flatten = Flatten()(lstm)\n",
    "        dense = Dense(len(self.words), activation='softmax')(flatten)\n",
    "        self.model = Model(inputs=input_tensor, outputs=dense)\n",
    "        optimizer = Adam(learning_rate=self.config.learning_rate)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    def sample(self, preds, temperature=1.0):\n",
    "        '''\n",
    "        当temperature=1.0时，模型输出正常\n",
    "        当temperature=0.5时，模型输出比较open\n",
    "        当temperature=1.5时，模型输出比较保守\n",
    "        在训练的过程中可以看到temperature不同，结果也不同\n",
    "        '''\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        return np.argmax(probas)\n",
    "\n",
    "    def generate_sample_result(self, epoch, logs):\n",
    "        '''训练过程中，每个epoch打印出当前的学习情况'''\n",
    "        # if epoch % 5 != 0:\n",
    "        #     return\n",
    "        print(\"\\n==================Epoch {}=====================\".format(epoch))\n",
    "        for diversity in [0.5, 1.0, 1.5]:\n",
    "            print(\"------------Diversity {}--------------\".format(diversity))\n",
    "            start_index = random.randint(0, len(self.files_content) - self.config.max_len - 1)\n",
    "            generated = ''\n",
    "            sentence = self.files_content[start_index: start_index + self.config.max_len]\n",
    "            generated += sentence\n",
    "            for i in range(20):\n",
    "                x_pred = np.zeros((1, self.config.max_len))\n",
    "                for t, char in enumerate(sentence[-6:]):\n",
    "                    x_pred[0, t] = self.word2numF(char)\n",
    "\n",
    "                preds = self.model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = self.sample(preds, diversity)\n",
    "                next_char = self.num2word[next_index]\n",
    "\n",
    "                generated += next_char\n",
    "                sentence = sentence + next_char\n",
    "            print(sentence)\n",
    "\n",
    "    def predict(self, text):\n",
    "        '''根据给出的文字，生成诗句'''\n",
    "        if not self.loaded_model:\n",
    "            return\n",
    "        with open(self.config.poetry_file, 'r', encoding='utf-8') as f:\n",
    "            file_list = f.readlines()\n",
    "        random_line = random.choice(file_list)\n",
    "        # 如果给的text不到四个字，则随机补全\n",
    "        if not text or len(text) != 4:\n",
    "            for _ in range(4 - len(text)):\n",
    "                random_str_index = random.randrange(0, len(self.words))\n",
    "                text += self.num2word.get(random_str_index) if self.num2word.get(random_str_index) not in [',', '。',\n",
    "                                                                                                           '，'] else self.num2word.get(\n",
    "                    random_str_index + 1)\n",
    "        seed = random_line[-(self.config.max_len):-1]\n",
    "\n",
    "        res = ''\n",
    "\n",
    "        seed = 'c' + seed\n",
    "\n",
    "        for c in text:\n",
    "            seed = seed[1:] + c\n",
    "            for j in range(5):\n",
    "                x_pred = np.zeros((1, self.config.max_len))\n",
    "                for t, char in enumerate(seed):\n",
    "                    x_pred[0, t] = self.word2numF(char)\n",
    "\n",
    "                preds = self.model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = self.sample(preds, 1.0)\n",
    "                next_char = self.num2word[next_index]\n",
    "                seed = seed[1:] + next_char\n",
    "            res += seed\n",
    "        return res\n",
    "\n",
    "    def data_generator(self):\n",
    "        '''生成器生成数据'''\n",
    "        i = 0\n",
    "        while 1:\n",
    "            x = self.files_content[i: i + self.config.max_len]\n",
    "            y = self.files_content[i + self.config.max_len]\n",
    "\n",
    "            puncs = [']', '[', '（', '）', '{', '}', '：', '《', '》', ':']\n",
    "            if len([i for i in puncs if i in x]) != 0:\n",
    "                i += 1\n",
    "                continue\n",
    "            if len([i for i in puncs if i in y]) != 0:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            y_vec = np.zeros(\n",
    "                shape=(1, len(self.words)),\n",
    "                dtype=np.bool\n",
    "            )\n",
    "            y_vec[0, self.word2numF(y)] = 1.0\n",
    "\n",
    "            x_vec = np.zeros(\n",
    "                shape=(1, self.config.max_len),\n",
    "                dtype=np.int32\n",
    "            )\n",
    "\n",
    "            for t, char in enumerate(x):\n",
    "                x_vec[0, t] = self.word2numF(char)\n",
    "            yield x_vec, y_vec\n",
    "            i += 1\n",
    "\n",
    "    def train(self):\n",
    "        '''训练模型'''\n",
    "        number_of_epoch = len(self.files_content) // self.config.batch_size\n",
    "\n",
    "        if not self.model:\n",
    "            self.build_model()\n",
    "\n",
    "        self.model.summary()\n",
    "\n",
    "        self.model.fit(\n",
    "            self.data_generator(),\n",
    "            verbose=True,\n",
    "            steps_per_epoch=self.config.batch_size,\n",
    "            epochs=number_of_epoch,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.ModelCheckpoint(self.config.weight_file, save_weights_only=False),\n",
    "                LambdaCallback(on_epoch_end=self.generate_sample_result)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "class Config(object):\n",
    "    poetry_file = 'C:\\\\Users\\\\drhu0\\\\poetry_generator_Keras-master\\\\poetry.txt'\n",
    "    weight_file = 'poetry_model.h5'\n",
    "    # 根据前六个字预测第七个字\n",
    "    max_len = 6\n",
    "    batch_size = 512\n",
    "    learning_rate = 0.001\n",
    "\n",
    "model = PoetryModel(Config)\n",
    "while 1:\n",
    "    text = input(\"text:\")\n",
    "    sentence = model.predict(text)\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3befe-7524-4501-9bc7-dac063c82c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
